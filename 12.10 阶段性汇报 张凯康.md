# 12.10 阶段性汇报 张凯康

标签（空格分隔）： istio 汇报

---
[TOC]
## 任务
1. 进行性能测试，对比K8S、istio、istio去除mixer，三种情况下裸跑Nginx，性能差距对比
2. 查找在此过程中暴露出来的问题。

## 第一次测试
### 数据及问题
数据一：
|环境|vCPU|CPU1|CPU2|CPU3|CPU4|CPU平均使用|QPS|
|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
|Istio|2*2vCPU|21.25|89.75|||55.5|1647|
|NoMixer|2*2vCPU|45|80|||62.5|3259|
|Istio|4*2vCPU|49|83|26|75|58.5|3455|
|NoMixer|4*2vCPU|30|98|34|27|47.16|5484|

>在这次测试中发现，不同CPU使用百分比差距极大，使用率高的CPU到达极限时，另一CPU使用率还很低。

数据二：
|环境|vCPU|线程数|连接数|CPU1|CPU2|CPU3|CPU4|CPU平均使用|QPS|ingressgateway|proxy|
|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
|NoMixer|4*2vCPU|4|64|26|98|36|28|47.75|5550|1.435|1.881|
|NoMixer|4*2vCPU|4|64|27|99|35|29|47.5|5550|1.49|1.956|
|NoMixer|4*2vCPU|4|64|92|93|45|95|81.25|9562|3.105|3.867|
|NoMixer|4*2vCPU|4|64|94|75|42|96|76.75|8924|1.435|3.603|

>通过这四组数据的对比可以看到，ingressgateway占用的CPU额度升高，CPU使用率顺势提高，经排查，发现在后两次压测中，Istio自动对ingressgateway的Pod数量进行了改变，从一个提高到了五个，分布在三个节点中，导致这三个CPU的使用率增加，相应QPS提高。 
但是在同样压测条件下上面两组数据没有做出相应的改变。
### **解决方案**
#### **问题原因**
1. ingressgateway组件负责网关功能，消耗大量CPU。
2. ingressgateway组件默认情况下部署在一个Node上，导致该Node的CPU使用率急速上升，成为性能瓶颈。
3. ingressgateway作为K8S的服务，拥有自动伸缩功能，其初始设置如下
   * 每一个pod限制最大CPU为2vCPU
   * 在达到pod限制CPU的80%使用率时，对ingressgateway进行pod伸缩，最大伸缩至5个。
4. 由于没有指定ingressgateway部署节点，其pod会随机部署在多个Node上。
5. 测试环境下单个节点CPU大小为2vCPU，部署了ingressgateway的节点还要负载业务服务和其他控制平面服务，导致该节点CPU使用率上升，成为性能瓶颈。
6. 经过继续排查，发现除了ingressgateway服务，其他的控制平面服务同样存在上述问题，目前在只部署Nginx服务的基础上，上述问题比较突出的组件是istio-telemetry (Mixer的其中一个组件)。

#### **解决方案**
1. 使用CPU、内存更高的EC2节点作为测试环境。目前使用2个m5.2xlarge（8vCPU），2个m5.xlarge（4vCPU）
2. 指定ingressgateway部署节点。将网关服务部署在两个性能更好的node上。将其他服务（包括控制平面服务）部署在其他两个node上。排除ingressgateway带来的性能干扰。
3. ingressgateway配置调整
   * 单Pod限制为2vCPU以内。
   * pod数量再5~8之间伸缩
   * 伸缩条件改为单Pod的CPU使用率达到50%
4. istio-telemetry配置调整
   * 单Pod限制为1vCPU以内
   * pod数量在1~5个之间伸缩
   * 伸缩条件改为单Pod的CPU使用率达到50%
5. Nginx Deployment配置调整
   * 固定为8个Pod
   * 每个Pod最大CPU使用为1vCPU
   * 平均分配到两个node上


## **第二次测试**
### **测试方案**
#### **测试计划**
1. 对K8S进行测试
2. 对Istio进行测试
3. 对Istio去除Mixer组件进行测试

#### **测试前准备**
1. 两台m5.2xlarge实例，运行istio-ingressgateway。
2. 两台m5.xlarge实例，负载nginx服务以及istio其他控制平面服务。
3. 观测工具准备：grafana、prometheus
4. 观测数据：
    * 各机器CPU使用情况
    * 各组件CPU使用情况
    * QPS
    * 平均、90、99延迟
    * 丢包情况记录
5. 测试条件
   * 最大性能测试，记录性能使用情况
   * CPU使用率60下观测数据
   * 对每一次测试，都对前一次测试时的最大性能条件进行测试，观测该条件下性能结果，以做对比。
6. 测试工具为`wrk`
#### **测试步骤**
1. 固定线程数，增加连接数，直到性能拐点。8、16、32、64、128、256。
2. 固定第一步连接数，增加线程数，直到性能拐点。1、2、4、8、16。
3. 限制节点CPU使用情况，重复1、2步骤。

```
$ wrk -t4 -c32 -d60s --latency http://<your-nginx-IP>
```

### **测试结果**

#### **K8S环境下**
|环境  |线程数 |连接数|测试时间|QPS|90延迟 |99延迟  |平均延迟|CPU使用率1|CPU使用率2|CPU平均使用率|
|:----:  |:----: |:----:|:----:  | :----: |:----: | :----: | :----:|:----:|:----:|:----:|
|K8S|2|256|90s|24765|12.01|14.48|10.23|56.5|48|52.25|

#### **Istio环境下**
>CPU 1 , CPU 2为工作节点
CPU 3，CPU 4为网关节点
相应CPU平均使用率为前两个节点CPU平均。

|环境  |线程数 |连接数|测试时间|QPS|90延迟 |99延迟  |平均延迟|CPU使用率1|CPU使用率2|CPU平均使用率|CPU使用率3|CPU使用率4|CPU平均使用率|telemetry|ingressgateway|policy|pilot|proxy|
|:----:  |:----: |:----:|:----:  | :----: |:----: | :----: | :----:|:----:|:----:|:----:|:----: | :----: | :----:|:----:|:----:|:----:|
|Istio|2|256|90s|26816|14.02|32.02|10.31|79|85.8|82.4|49.6|58.4|54|1.856|8.14|0.03|0.0188|8.24|
|Istio|2|64|90s|20953|5.375|11.655|3.59|64.75|61.25|63|46.25|40.75|43.5|1.453|6.16|0.03|0.004|6.32|

#### **Istio去除Mixer组件**

|环境  |线程数 |连接数|测试时间|QPS|90延迟 |99延迟  |平均延迟|CPU使用率1|CPU使用率2|CPU平均使用率|CPU使用率3|CPU使用率4|CPU平均使用率|ingressgateway|pilot|proxy|
|:----:  |:----: |:----:|:----:  | :----: |:----: | :----: | :----:|:----:|:----:|:----:|:----: | :----: | :----:|:----:|:----:|:----:|
|NoMixer|2|256|90s|25779|12.48|17.57|9.95|59.75|61|60.375|47|55.5|51.25|7.675|0.003|7.60|
|NoMixer|2|300|90s|27789|12.95|16.14|10.78|67.5|64|65.7|54.75|62.25|58.5|8.155|0.003|8.09|




